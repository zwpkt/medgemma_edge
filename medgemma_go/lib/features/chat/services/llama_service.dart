import 'dart:io';
import 'package:flutter/material.dart';
import 'package:flutter_llama/flutter_llama.dart';
import '../../../core/constants/model_config.dart';

class LlamaService {
  // âœ… å¤šæ¨¡æ€ä¸“ç”¨å•ä¾‹
  final FlutterLlamaMultimodal _multimodal = FlutterLlamaMultimodal.instance;

  bool _isModelLoaded = false;
  bool get isModelLoaded => _isModelLoaded;

  String? _currentTextModelPath;
  String? _currentMmprojPath;

  // âœ… åŠ è½½ SandLogicTechnologies åŒæ–‡ä»¶å¤šæ¨¡æ€æ¨¡å‹
  Future<void> loadMultimodalModel() async {
    if (_isModelLoaded) return;

    try {
      _currentTextModelPath = await ModelConfig.textModelPath;
      _currentMmprojPath = await ModelConfig.mmprojPath;

      debugPrint('ğŸš€ å¼€å§‹åŠ è½½å¤šæ¨¡æ€æ¨¡å‹...');
      debugPrint('   ğŸ“ æ¨¡å‹ç›®å½•: ${await ModelConfig.getModelDirPathForAdb()}');
      debugPrint('   ğŸ“„ æ–‡æœ¬æ¨¡å‹: $_currentTextModelPath');
      debugPrint('   ğŸ–¼ï¸  mmproj: $_currentMmprojPath');

      // 2. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
      final textFile = File(_currentTextModelPath!);
      final mmprojFile = File(_currentMmprojPath!);

      if (!await textFile.exists()) {
        throw Exception('âŒ æ–‡æœ¬æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨\n'
            'è¯·ä½¿ç”¨ADBæ¨é€æ–‡ä»¶åˆ°: ${await ModelConfig.getModelDirPathForAdb()}');
      }
      if (!await mmprojFile.exists()) {
        throw Exception('âŒ æŠ•å½±å™¨æ–‡ä»¶ä¸å­˜åœ¨\n'
            'è¯·ä½¿ç”¨ADBæ¨é€æ–‡ä»¶åˆ°: ${await ModelConfig.getModelDirPathForAdb()}');
      }

      // 3. æ˜¾ç¤ºæ–‡ä»¶å¤§å°
      await ModelConfig.printFileSizes();

      final config = MultimodalConfig(
        textModelPath: _currentTextModelPath!,
        mmprojPath: _currentMmprojPath!,
        enableVision: true,
        useGpuForMultimodal: true,
        maxImageSize: 448,
      );

      debugPrint('âš™ï¸ åŠ è½½é…ç½®å®Œæˆï¼Œå¼€å§‹åŠ è½½æ¨¡å‹...');
      final success = await _multimodal.loadMultimodalModel(config);

      if (success) {
        _isModelLoaded = true;
        debugPrint('âœ…ã€å¤šæ¨¡æ€æ¨¡å‹åŠ è½½æˆåŠŸã€‘');
      } else {
        throw Exception('loadMultimodalModel è¿”å› false');
      }
    } catch (e) {
      debugPrint('âŒ å¤šæ¨¡æ€æ¨¡å‹åŠ è½½å¤±è´¥: $e');
      _isModelLoaded = false;
      rethrow;
    }
  }

  // ---------- âœ…ã€æ–¹æ¡ˆ1ã€‘describeImageï¼ˆæœ€ç®€æ´ï¼Œæ¨èï¼ï¼‰----------
  Future<String> describeImage({
    required String imagePath,
    String prompt = 'è¯·è¯¦ç»†æè¿°è¿™å¼ åŒ»ç–—å›¾åƒä¸­çš„å‘ç°ã€‚',
    int maxTokens = 1024,
    double temperature = 0.7,
  }) async {
    if (!_isModelLoaded) await loadMultimodalModel();

    try {
      debugPrint('ğŸ–¼ï¸ã€describeImageã€‘å¼€å§‹');

      final params = GenerationParams(
        prompt: '',  // å¿…é¡»ä¼ ç©ºå­—ç¬¦ä¸²
        maxTokens: maxTokens,
        temperature: temperature,
        topP: 0.95,
        topK: 40,
        repeatPenalty: 1.1,
      );

      final response = await _multimodal.describeImage(
        imagePath,
        prompt,
        params: params,
      );

      return response.text.trim();
    } catch (e) {
      debugPrint('âŒ describeImage å¤±è´¥: $e');
      rethrow;
    }
  }

  // ---------- âœ…ã€æ–¹æ¡ˆ2ã€‘generateMultimodalï¼ˆé€šç”¨æ–¹æ¡ˆï¼‰- å·²ä¿®å¤ type å‚æ•° ----------
  Future<String> generateWithImage({
    required String prompt,
    required String imagePath,
    int maxTokens = 1024,
    double temperature = 0.7,
  }) async {
    if (!_isModelLoaded) await loadMultimodalModel();

    try {
      debugPrint('ğŸ–¼ï¸ã€generateMultimodalã€‘å¼€å§‹');

      // âœ…ã€å…³é”®ä¿®å¤ã€‘å¿…é¡»æŒ‡å®š type = MultimodalType.textAndImageï¼
      final input = MultimodalInput(
        type: MultimodalType.mixed,  // ğŸ‘ˆ å¿…é¡»æ·»åŠ ï¼
        text: prompt,
        imagePath: imagePath,
      );

      final params = GenerationParams(
        prompt: '',  // å¿…é¡»ä¼ ç©ºå­—ç¬¦ä¸²
        maxTokens: maxTokens,
        temperature: temperature,
        topP: 0.95,
        topK: 40,
        repeatPenalty: 1.1,
      );

      final response = await _multimodal.generateMultimodal(
        input,
        params,
      );

      return response.text.trim();
    } catch (e) {
      debugPrint('âŒ generateWithImage å¤±è´¥: $e');
      rethrow;
    }
  }

  // ---------- âœ…ã€æ–¹æ¡ˆ3ã€‘æµå¼å¤šæ¨¡æ€ - å·²ä¿®å¤ type å‚æ•° ----------
  Stream<String> generateWithImageStreaming({
    required String prompt,
    required String imagePath,
    int maxTokens = 1024,
    double temperature = 0.7,
  }) async* {
    if (!_isModelLoaded) await loadMultimodalModel();

    try {
      debugPrint('ğŸ–¼ï¸ã€æµå¼å¤šæ¨¡æ€ã€‘å¼€å§‹');

      // âœ…ã€å…³é”®ä¿®å¤ã€‘æµå¼ç‰ˆæœ¬åŒæ ·éœ€è¦ type
      final input = MultimodalInput(
        type: MultimodalType.mixed,  // ğŸ‘ˆ å¿…é¡»æ·»åŠ ï¼
        text: prompt,
        imagePath: imagePath,
      );

      final params = GenerationParams(
        prompt: '',  // å¿…é¡»ä¼ ç©ºå­—ç¬¦ä¸²
        maxTokens: maxTokens,
        temperature: temperature,
        topP: 0.95,
        topK: 40,
        repeatPenalty: 1.1,
      );

      await for (final response in _multimodal.generateMultimodalStream(
        input,
        params,
      )) {
        yield response.text;
      }
    } catch (e) {
      debugPrint('âŒ æµå¼å¤šæ¨¡æ€å¤±è´¥: $e');
      rethrow;
    }
  }

  // ---------- âœ… çº¯æ–‡æœ¬ç”Ÿæˆï¼ˆä¸éœ€è¦ typeï¼‰----------
  Future<String> generateText({
    required String prompt,
    int maxTokens = 1024,
    double temperature = 0.7,
  }) async {
    if (!_isModelLoaded) await loadMultimodalModel();

    try {
      // âœ… çº¯æ–‡æœ¬ï¼šä½¿ç”¨ä¸å¸¦ imagePath çš„ MultimodalInput
      final input = MultimodalInput(
        type: MultimodalType.text,  // ğŸ‘ˆ çº¯æ–‡æœ¬ç±»å‹
        text: prompt,
      );

      final params = GenerationParams(
        prompt: prompt,  // çº¯æ–‡æœ¬æ—¶å¿…é¡»ä¼ çœŸå® prompt
        maxTokens: maxTokens,
        temperature: temperature,
        topP: 0.95,
        topK: 40,
        repeatPenalty: 1.1,
      );

      final response = await _multimodal.generateMultimodal(
        input,
        params,
      );

      return response.text.trim();
    } catch (e) {
      debugPrint('âŒ æ–‡æœ¬æ¨ç†å¤±è´¥: $e');
      rethrow;
    }
  }

  // ---------- âœ… æµå¼çº¯æ–‡æœ¬ ----------
  Stream<String> generateTextStreaming({
    required String prompt,
    int maxTokens = 1024,
    double temperature = 0.7,
  }) async* {
    if (!_isModelLoaded) await loadMultimodalModel();

    try {
      final input = MultimodalInput(
        type: MultimodalType.text,  // ğŸ‘ˆ çº¯æ–‡æœ¬ç±»å‹
        text: prompt,
      );

      final params = GenerationParams(
        prompt: prompt,
        maxTokens: maxTokens,
        temperature: temperature,
      );

      await for (final response in _multimodal.generateMultimodalStream(
        input,
        params,
      )) {
        yield response.text;
      }
    } catch (e) {
      debugPrint('âŒ æ–‡æœ¬æµå¼å¤±è´¥: $e');
      rethrow;
    }
  }

  // âœ… åœæ­¢ç”Ÿæˆ
  Future<void> stopGeneration() async {
    if (_isModelLoaded) {
      await _multimodal.stopMultimodalGeneration();
      debugPrint('â¹ï¸ ç”Ÿæˆå·²åœæ­¢');
    }
  }

  // âœ… å¸è½½æ¨¡å‹
  Future<void> unloadMultimodalModel() async {
    if (_isModelLoaded) {
      await _multimodal.unloadMultimodalModel();
      _isModelLoaded = false;
      debugPrint('âœ… å¤šæ¨¡æ€æ¨¡å‹å·²å¸è½½');
    }
  }
}